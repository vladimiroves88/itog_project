{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evgeniy/.pyenv/versions/3.12.4/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from transformers import BertTokenizer, AutoTokenizer, BertForSequenceClassification, AutoModelForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from transformers import DataCollatorWithPadding\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_excel('6_label_100_sample.xlsx')\n",
    "#df = pd.read_excel('2108(1000 sample).xlsx')\n",
    "df = pd.read_excel('1_for_train_1000_sample.xlsx')\n",
    "df_real_val = pd.read_excel('1_for_real_val.xlsx')\n",
    "#df_real_val = pd.read_excel('for_inferense_august.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_model = 'ai-forever/ruBert-large'\n",
    "#base_model = 'ai-forever/ruRoberta-large'\n",
    "#base_model = 'bert-base-uncased'\n",
    "#base_model = 'ai-forever/ru-en-RoSBERTa'\n",
    "#base_model = 'microsoft/Multilingual-MiniLM-L12-H384'\n",
    "base_model = 't-bank-ai/response-toxicity-classifier-base'\n",
    "#base_model = 'DeepPavlov/distilrubert-tiny-cased-conversational'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 762/762 [00:00<00:00, 17539.85 examples/s]\n",
      "Map: 100%|██████████| 191/191 [00:00<00:00, 17248.25 examples/s]\n",
      "Map: 100%|██████████| 3683/3683 [00:00<00:00, 14883.23 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "data = Dataset.from_dict({'text': df['Text'], 'label': df['Label']}).train_test_split(test_size=0.2, seed=42)\n",
    "data_real_val = Dataset.from_dict({'text': df_real_val['Text']})\n",
    "data_tokenized = data.map(lambda x: tokenizer(x['text'], truncation=True, max_length=512), batched=True, remove_columns=['text'])\n",
    "data_real_val_tokenized = data_real_val.map(lambda x: tokenizer(x['text'], truncation=True, max_length=512), batched=True, remove_columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "train_dataloader = DataLoader(data_tokenized['train'], shuffle=True, batch_size=8, collate_fn=collator)\n",
    "val_dataloader = DataLoader(data_tokenized['test'], shuffle=False, batch_size=8, collate_fn=collator)\n",
    "real_val_dataloader = DataLoader(data_real_val_tokenized, shuffle=False, batch_size=8, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at t-bank-ai/response-toxicity-classifier-base and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([4, 768]) in the checkpoint and torch.Size([6, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([4]) in the checkpoint and torch.Size([6]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(base_model, num_labels=6, ignore_mismatched_sizes=True) # for t-bank-ai/response-toxicity-classifier-base\n",
    "#model = AutoModelForSequenceClassification.from_pretrained(base_model, num_labels=6)\n",
    "optimizer = Adam(model.parameters(), lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "#del model\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - recent train loss: 1.83\n",
      "train loss: 1.83, eval loss: 1.78,  accuracy: 0.12\n",
      "Epoch 2/20 - recent train loss: 1.74\n",
      "train loss: 1.74, eval loss: 1.71,  accuracy: 0.34\n",
      "Epoch 3/20 - recent train loss: 1.66\n",
      "train loss: 1.66, eval loss: 1.61,  accuracy: 0.43\n",
      "Epoch 4/20 - recent train loss: 1.53\n",
      "train loss: 1.54, eval loss: 1.46,  accuracy: 0.45\n",
      "Epoch 5/20 - recent train loss: 1.41\n",
      "train loss: 1.41, eval loss: 1.35,  accuracy: 0.48\n",
      "Epoch 6/20 - recent train loss: 1.29\n",
      "train loss: 1.29, eval loss: 1.27,  accuracy: 0.53\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(f'runs/{base_model}, batch_size = {train_dataloader.batch_size}, date = {datetime.now().strftime(\"%Y-%m-%d, %H:%M\")}')\n",
    "losses = []\n",
    "n_epoch = 20\n",
    "train_batch_count = len(train_dataloader)\n",
    "val_batch_count = len(val_dataloader)\n",
    "for epoch in range(n_epoch):\n",
    "    model.train()\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        out = model(**batch.to(model.device))\n",
    "        out.loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(out.loss.item())\n",
    "    writer.add_scalar(\"Loss/train\", np.mean(losses[-train_batch_count:]), epoch+1)    \n",
    "    print(f'Epoch {epoch + 1}/{n_epoch} - recent train loss: {np.mean(losses[-train_batch_count:]):2.2f}')\n",
    "\n",
    "    model.eval()\n",
    "    eval_losses = []\n",
    "    eval_preds = []\n",
    "    eval_targets = []\n",
    "    for batch in val_dataloader:\n",
    "        with torch.no_grad():\n",
    "            out = model(**batch.to(model.device))\n",
    "        eval_losses.append(out.loss.item())\n",
    "        eval_preds.extend(out.logits.argmax(1).tolist())\n",
    "        eval_targets.extend(batch['labels'].tolist())\n",
    "    writer.add_scalar(\"Loss/val\", np.mean(eval_losses), epoch+1) \n",
    "    writer.add_scalar(\"Accuracy/val\", np.mean(np.array(eval_targets) == eval_preds), epoch+1) \n",
    "    \n",
    "\n",
    "    print(f'train loss: {np.mean(losses[-100:]):2.2f}, eval loss: {np.mean(eval_losses):2.2f},  accuracy: {np.mean(np.array(eval_targets) == eval_preds):2.2f}')\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "eval_losses = []\n",
    "eval_preds = []\n",
    "eval_targets = []\n",
    "\n",
    "mistake = pd.DataFrame(columns=['text', 'preds', 'true', 'probs'])\n",
    "\n",
    "for batch in val_dataloader:\n",
    "        with torch.no_grad():\n",
    "            out = model(**batch.to(model.device))\n",
    "        eval_losses.append(out.loss.item())\n",
    "        eval_preds.extend(out.logits.argmax(1).tolist())\n",
    "        eval_targets.extend(batch['labels'].tolist())\n",
    "\n",
    "        batch_error_df = pd.DataFrame({'text': list(map(lambda x: tokenizer.decode(x, skip_special_tokens=True), batch['input_ids'])), 'preds': out.logits.argmax(1).tolist(), 'true': batch['labels'].tolist(), \n",
    "                                       'probs': map(lambda x: [round(val, 2) for val in torch.nn.Softmax(dim=0)(x.cpu()).tolist()], out.logits),\n",
    "                                       'max_prob': map(lambda x: max([round(val, 2) for val in torch.nn.Softmax(dim=0)(x.cpu()).tolist()]), out.logits),\n",
    "                                       'entropy': map(lambda y: round(entropy(y, base=2), 2), list(map(lambda x: [round(val, 2) for val in torch.nn.Softmax(dim=0)(x.cpu()).tolist()], out.logits)))})\n",
    "        mistake = pd.concat([mistake, batch_error_df[batch_error_df['preds'] != batch_error_df['true']]])\n",
    "\n",
    "\n",
    "report = classification_report(eval_targets, eval_preds, target_names=[\"Инцидент\", \"Создание УЗ\", \"Восстановление УЗ\", \"Добавление ПФ\", \"Изменение реквизитов\", \"Блокировка пользователя\"])\n",
    "print(report)\n",
    "pd.options.display.max_colwidth = 200\n",
    "mistake.reset_index(inplace=True, drop=True)\n",
    "mistake\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.cpu()\n",
    "model.eval()\n",
    "predictions = pd.DataFrame(columns=['text', 'preds', 'probs'])\n",
    "for batch in real_val_dataloader:\n",
    "        with torch.no_grad():\n",
    "            out = model(**batch.to(model.device))\n",
    "\n",
    "        pred_batch = pd.DataFrame({'text': list(map(lambda x: tokenizer.decode(x, skip_special_tokens=True), batch['input_ids'])), 'preds': out.logits.argmax(1).tolist(), \n",
    "                                   'probs': list(map(lambda x: [round(val, 2) for val in torch.nn.Softmax(dim=0)(x.cpu()).tolist()], out.logits)),\n",
    "                                   'max_prob': list(map(lambda x: max([round(val, 2) for val in torch.nn.Softmax(dim=0)(x.cpu()).tolist()]), out.logits)),\n",
    "                                   'entropy': map(lambda y: round(entropy(y, base=2), 2), list(map(lambda x: [round(val, 2) for val in torch.nn.Softmax(dim=0)(x.cpu()).tolist()], out.logits)))})\n",
    "        predictions = pd.concat([predictions, pred_batch])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[(predictions['preds'] != 0) & (predictions['max_prob'] > 0.9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(predictions['entropy'].mean(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['preds'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[predictions['preds'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
